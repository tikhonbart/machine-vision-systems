{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализация транспонированной свертки\n",
    "def convolution_transpose(input_data, kernel, stride=1):\n",
    "    input_channels, input_height, input_width = input_data.shape\n",
    "    kernel_channels, kernel_height, kernel_width = kernel.shape\n",
    "    \n",
    "    output_height = (input_height - 1) * stride + kernel_height\n",
    "    output_width = (input_width - 1) * stride + kernel_width\n",
    "    output = np.zeros((input_channels, output_height, output_width))\n",
    "    \n",
    "    for c in range(input_channels):\n",
    "        for i in range(input_height):\n",
    "            for j in range(input_width):\n",
    "                output[c, i * stride:i * stride + kernel_height, j * stride:j * stride + kernel_width] += kernel[c] * input_data[c, i, j]\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализация транспонированной свертки методом билинейной интерполяции\n",
    "def transpose_conv2D(input, weight, bias=None, stride=1, padding=0, output_padding=0, groups=1, dilation=1):\n",
    "    # Получение выходных размеров и пустого массива для результатов\n",
    "    batch_size, in_channels, img_height, img_width = input.shape\n",
    "    out_channels, in_channels, kernel_height, kernel_width = weight.shape\n",
    "\n",
    "    # Вычисление размеров выходных данных после транспонированной свертки\n",
    "    h_out = (img_height - 1) * stride - 2 * padding + kernel_height + output_padding\n",
    "    w_out = (img_width - 1) * stride - 2 * padding + kernel_width + output_padding\n",
    "\n",
    "    # Создание пустого массива для хранения результатов\n",
    "    result = np.zeros((batch_size, out_channels, h_out, w_out))\n",
    "\n",
    "    # Проверка и применение заполнения, если оно задано\n",
    "    if padding > 0:\n",
    "        input = np.pad(input, padding, mode='constant')\n",
    "\n",
    "    batch_size, out_channels, H_out, W_out = result.shape\n",
    "\n",
    "    # Циклы для обработки каждого пикселя выходного изображения\n",
    "    for batch in range(batch_size):\n",
    "        for channel_o in range(out_channels):\n",
    "            for h_o in range(H_out):\n",
    "                for w_o in range(W_out):\n",
    "                    for in_c in range(input.shape[1]):\n",
    "                        for kern_h in range(weight.shape[2]):\n",
    "                            for kern_w in range(weight.shape[3]):\n",
    "                                # Вычисление координат входного пикселя\n",
    "                                ii = h_o + padding - kern_h * dilation\n",
    "                                jj = w_o + padding - kern_w * dilation\n",
    "\n",
    "                                # Проверка попадания в границы входных данных\n",
    "                                if ii >= 0 and jj >= 0 and ii < input.shape[2] * stride and jj < input.shape[3] * stride and (ii % stride == 0) and (jj % stride == 0):\n",
    "                                    ii //= stride\n",
    "                                    jj //= stride\n",
    "                                    # Выполнение транспонированной свертки и накопление результата\n",
    "                                    result[batch, channel_o, h_o, w_o] += np.multiply(input[batch, in_c, ii, jj], weight[channel_o, in_c, kern_h, kern_w])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты совпадают: Успех!\n"
     ]
    }
   ],
   "source": [
    "def test_compare_with_torch():\n",
    "    image = torch.randn(1, 1, 5, 5) \n",
    "    weight = torch.randn(1, 1, 3, 3)\n",
    "        \n",
    "    myConv2D_T = torch.from_numpy(transpose_conv2D(image.numpy(), weight.numpy()))\n",
    "\n",
    "\n",
    "    torchConv2D_T = F.conv_transpose2d(image, weight)\n",
    "\n",
    "    myConv2D_T = myConv2D_T.to(torchConv2D_T.dtype)\n",
    "\n",
    "    # Сравнение результатов\n",
    "    if np.allclose(myConv2D_T, torchConv2D_T):\n",
    "        print(\"Результаты совпадают: Успех!\")\n",
    "    else:\n",
    "        print(\"Результаты НЕ совпадают\")\n",
    "\n",
    "test_compare_with_torch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты совпадают: Успех!\n"
     ]
    }
   ],
   "source": [
    "def test_compare_with_torch():\n",
    "    image = torch.randn(1, 1, 5, 5) \n",
    "    weight = torch.randn(1, 1, 3, 3)\n",
    "        \n",
    "    myConv2D_T = torch.from_numpy(transpose_conv2D(image.numpy(), weight.numpy()))\n",
    "\n",
    "\n",
    "    torchConv2D_T = F.conv_transpose2d(image, weight)\n",
    "\n",
    "    myConv2D_T = myConv2D_T.to(torchConv2D_T.dtype)\n",
    "\n",
    "    # Сравнение результатов\n",
    "    if np.allclose(myConv2D_T, torchConv2D_T):\n",
    "        print(\"Результаты совпадают: Успех!\")\n",
    "    else:\n",
    "        print(\"Результаты НЕ совпадают\")\n",
    "\n",
    "test_compare_with_torch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты совпадают: Успех!\n"
     ]
    }
   ],
   "source": [
    "def test_compare_with_torch():\n",
    "    image = torch.randn(1, 1, 5, 5) \n",
    "    weight = torch.randn(1, 1, 3, 3)\n",
    "        \n",
    "    myConv2D_T = torch.from_numpy(transpose_conv2D(image.numpy(), weight.numpy()))\n",
    "\n",
    "\n",
    "    torchConv2D_T = F.conv_transpose2d(image, weight)\n",
    "\n",
    "    myConv2D_T = myConv2D_T.to(torchConv2D_T.dtype)\n",
    "\n",
    "    # Сравнение результатов\n",
    "    if np.allclose(myConv2D_T, torchConv2D_T):\n",
    "        print(\"Результаты совпадают: Успех!\")\n",
    "    else:\n",
    "        print(\"Результаты НЕ совпадают\")\n",
    "\n",
    "test_compare_with_torch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
